{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partialmethod\n",
    "from scipy.stats import truncnorm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Seq_Coding={'A':[1.,0.,0.,0.],'T':[0.,1.,0.,0.],'C':[0.,0.,1.,0.],'G':[0.,0.,0.,1.],'N':[0.25,0.25,0.25,0.25]}\n",
    "class NanoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,path,use_file):\n",
    "        samples_dic={}\n",
    "        with open(path+'/'+use_file+'.txt','r') as f:\n",
    "            for line in f.readlines():\n",
    "                f_name,label=line.strip().split()\n",
    "                with open(path+'/'+f_name+'.index') as f2:\n",
    "                    for line2 in f2.readlines():\n",
    "                        sample,start,end=line2.strip().split('\\t')\n",
    "                        if sample not in samples_dic:\n",
    "                            samples_dic[sample]=[]\n",
    "                        samples_dic[sample].append((f_name,int(start),int(end),int(label)))\n",
    "        self.path=path\n",
    "        self.samples_keys=list(samples_dic.keys())\n",
    "        self.samples_dic=samples_dic\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        R_dicts=[]\n",
    "        for single_sample in self.samples_dic[self.samples_keys[index]]:\n",
    "            file,seek_start,seek_end,label=single_sample\n",
    "            R_dict={'seq_feature':[],'seq_mask':[],'nano_feature':[],'nano_mask':[],'label':label}\n",
    "            with open(self.path+'/'+file+'.json') as f:\n",
    "                f.seek(seek_start,0)\n",
    "                json_str=f.read(seek_end-seek_start)\n",
    "                Ls=json_str.strip().split('\\n')\n",
    "                for each in json.loads(Ls[0]):\n",
    "                    R_dict['seq_feature'].append(Seq_Coding[each])\n",
    "                    if each=='N':\n",
    "                        R_dict['seq_mask'].append(0)\n",
    "                    else:\n",
    "                        R_dict['seq_mask'].append(1)\n",
    "\n",
    "                for L in Ls[1:]:\n",
    "                    L_data=json.loads(L)\n",
    "                    t_feature=[]\n",
    "                    t_mask=[]\n",
    "                    for each in L_data:\n",
    "                        if each[0]<0:\n",
    "                            t_feature.append([0,0,0])\n",
    "                            t_mask.append(0)\n",
    "                        else:\n",
    "                            t_feature.append(each)\n",
    "                            t_mask.append(1)\n",
    "                    R_dict['nano_mask'].append(t_mask)\n",
    "                    R_dict['nano_feature'].append(t_feature)\n",
    "            for key in R_dict:\n",
    "                R_dict[key]=torch.tensor(R_dict[key])\n",
    "            R_dicts.append(R_dict)\n",
    "        return R_dicts                \n",
    "    def __len__(self):\n",
    "        return len(self.samples_dic)\n",
    "\n",
    "class FlattenedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,original_dataset):\n",
    "        self.flattened_data=[]\n",
    "        for data in original_dataset:\n",
    "            self.flattened_data.extend(data)\n",
    "    def __len__(self):\n",
    "        return len(self.flattened_data)\n",
    "    def __getitem__(self,index):\n",
    "        if isinstance(index,(list,np.ndarray)):\n",
    "            return [self.flattened_data[i] for i in index]\n",
    "        else:\n",
    "            return self.flattened_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(flattened_train_set) 3799\n",
      "len(flattened_val_set) 1282\n",
      "len(flattened_test_set) 1298\n"
     ]
    }
   ],
   "source": [
    "RELOAD=0\n",
    "if RELOAD==1:\n",
    "    dataset=NanoDataset('./edata/DataSet/m6A','use_files')\n",
    "    train_size=int(len(dataset)*0.6)\n",
    "    val_size=int(len(dataset)*0.2)\n",
    "    test_size=len(dataset)-val_size-train_size\n",
    "    train_set,val_set,test_set=torch.utils.data.random_split(dataset,[train_size,val_size,test_size])\n",
    "    flattened_train_set=FlattenedDataset(train_set)\n",
    "    flattened_val_set=FlattenedDataset(val_set)\n",
    "    flattened_test_set=FlattenedDataset(test_set)\n",
    "    print('len(flattened_train_set)',len(flattened_train_set))\n",
    "    print('len(flattened_val_set)',len(flattened_val_set))\n",
    "    print('len(flattened_test_set)',len(flattened_test_set))\n",
    "\n",
    "    #with open('./edata/Save_DataSet/m6A_NSWord_train_set.pkl','wb') as f:\n",
    "        #pickle.dump(flattened_train_set,f)\n",
    "    #with open('./edata/Save_DataSet/m6A_NSWord_val_set.pkl','wb') as f:\n",
    "        #pickle.dump(flattened_val_set,f)\n",
    "   # with open('./edata/Save_DataSet/m6A_NSWord_test_set.pkl','wb') as f:\n",
    "        #pickle.dump(flattened_test_set,f)\n",
    "    train_loader=DataLoader(flattened_train_set,batch_size=5,shuffle=True)\n",
    "    val_loader=DataLoader(flattened_val_set,batch_size=5,shuffle=True)\n",
    "    test_loader=DataLoader(flattened_test_set,batch_size=5,shuffle=True)\n",
    "else:\n",
    "    with open('./edata/Save_DataSet/m6A_NSWord_train_set.pkl','rb') as f:\n",
    "        flattened_train_set=pickle.load(f)\n",
    "    with open('./edata/Save_DataSet/m6A_NSWord_val_set.pkl','rb') as f:\n",
    "        flattened_val_set=pickle.load(f)\n",
    "    with open('./edata/Save_DataSet/m6A_NSWord_test_set.pkl','rb') as f:\n",
    "        flattened_test_set=pickle.load(f)\n",
    "    print('len(flattened_train_set)',len(flattened_train_set))\n",
    "    print('len(flattened_val_set)',len(flattened_val_set))\n",
    "    print('len(flattened_test_set)',len(flattened_test_set))\n",
    "    \n",
    "    train_loader=DataLoader(flattened_train_set,batch_size=5,shuffle=True)\n",
    "    val_loader=DataLoader(flattened_val_set,batch_size=5,shuffle=True)\n",
    "    test_loader=DataLoader(flattened_test_set,batch_size=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BoxPlot Drawing Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##Extra: For box plot drawing\n",
    "#Run these part only if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def box_plot_drawing_prepare(dataset,required_K5,name):\n",
    "    plot_frame=pd.DataFrame(columns=['feature','value','position','modification'])\n",
    "    L=len(dataset)\n",
    "    count=0\n",
    "    for el in tqdm(dataset):\n",
    "        count+=1\n",
    "        if count>L:\n",
    "            break\n",
    "        K5=''\n",
    "        mid=int((len(el['seq_feature'])-1)/2)\n",
    "        for each in el['seq_feature'][mid-2:mid+2+1]:\n",
    "            if each[0].item()==1:\n",
    "                K5+='A'\n",
    "            elif each[1].item()==1:\n",
    "                K5+='T'\n",
    "            elif each[2].item()==1:\n",
    "                K5+='C'\n",
    "            elif each[3].item()==1:\n",
    "                K5+='G'\n",
    "        if K5!=required_K5:\n",
    "            continue\n",
    "\n",
    "        for each_feature in el['nano_feature']:\n",
    "            mid=int((len(each_feature)-1)/2)\n",
    "            for rel in [-2,-1,0,1,2]:\n",
    "                Lis=list(each_feature[mid+rel].numpy())\n",
    "                if sum(Lis)>0.01:\n",
    "                    plot_frame.loc[len(plot_frame)]=['event_mean',Lis[0],rel,el['label'].item()]\n",
    "                    plot_frame.loc[len(plot_frame)]=['event_stdv',Lis[1],rel,el['label'].item()]\n",
    "                    plot_frame.loc[len(plot_frame)]=['event_length',Lis[2],rel,el['label'].item()]\n",
    "    plot_frame.to_csv('./edata/Save_for_drawing/'+name+'_box_plot.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6379"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=NanoDataset('./edata/DataSet/m6A','use_files')\n",
    "flattened_dataset=FlattenedDataset(dataset)\n",
    "print(len(flattened_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sample_set,_=torch.utils.data.random_split(dataset=flattened_dataset,lengths=[1000,len(flattened_dataset)-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [07:38<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#box_plot_drawing_prepare(sample_set,'GGACT','m6A_GGACT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#box_plot_drawing_prepare(sample_set,'GAACT','m6A_GAACT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tools for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def glorot_uniform_init_(weights):\n",
    "    nn.init.xavier_uniform_(weights,gain=1)\n",
    "def zero_init_(weights):\n",
    "    with torch.no_grad():\n",
    "        weights.fill_(0.0)\n",
    "def permute_final_dims(tensor,inds):\n",
    "    zero_index=-1*len(inds)\n",
    "    first_inds=list(range(len(tensor.shape[:zero_index])))\n",
    "    return tensor.permute(first_inds+[zero_index+i for i in inds])\n",
    "def flatten_final_dims(t,no_dims):\n",
    "    return t.reshape(t.shape[:-no_dims]+(-1,))\n",
    "def relu_init_(weights,scale=2.0):\n",
    "    shape=weights.shape\n",
    "    _,f=shape\n",
    "    scale=scale/max(1,f)\n",
    "    a=-2\n",
    "    b=2\n",
    "    std=math.sqrt(scale)/truncnorm.std(a=a,b=b,loc=0,scale=1)\n",
    "    size=1\n",
    "    for n in shape:\n",
    "        size=size*n\n",
    "    samples=truncnorm.rvs(a=a,b=b,loc=0,scale=std,size=size)\n",
    "    samples=np.reshape(samples,shape)\n",
    "    with torch.no_grad():\n",
    "        weights.copy_(torch.tensor(samples,device=weights.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Linear):\n",
    "    def __init__(self,in_dim,out_dim,bias=True,init=\"zero\"):\n",
    "        super(Linear,self).__init__(in_dim,out_dim,bias=bias)\n",
    "        if bias:\n",
    "            with torch.no_grad():\n",
    "                self.bias.fill_(0)\n",
    "        with torch.no_grad():\n",
    "            if init=='zero':\n",
    "                zero_init_(self.weight)\n",
    "            elif init=='glorot':\n",
    "                glorot_uniform_init_(self.weight)\n",
    "            elif init=='relu':\n",
    "                relu_init_(self.weight)\n",
    "            elif init=='gating':\n",
    "                zero_init_(self.weight)\n",
    "                if bias:\n",
    "                    self.bias.fill_(1.0)\n",
    "            else:\n",
    "                 glorot_uniform_init_(self.weight)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,c_in,eps=1e-5):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.c_in=(c_in,)\n",
    "        self.eps=eps\n",
    "        self.weight=nn.Parameter(torch.ones(c_in))\n",
    "        self.bias=nn.Parameter(torch.zeros(c_in))\n",
    "    def forward(self,x): \n",
    "        out=nn.functional.layer_norm(x,self.c_in,self.weight,self.bias,self.eps)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self,r,batch_dim):\n",
    "        super(Dropout,self).__init__()\n",
    "        self.r=r\n",
    "        if type(batch_dim)==int:\n",
    "            batch_dim=[batch_dim]\n",
    "        self.batch_dim=batch_dim\n",
    "        self.dropout=nn.Dropout(r)\n",
    "    def forward(self,x):\n",
    "        shape=list(x.shape)\n",
    "        if self.batch_dim is not None:\n",
    "            for bd in self.batch_dim:\n",
    "                shape[bd]=1\n",
    "        mask=x.new_ones(shape)\n",
    "        mask=self.dropout(mask)\n",
    "        x*=mask\n",
    "        return x\n",
    "class DropoutRowwise(Dropout):\n",
    "    __init__=partialmethod(Dropout.__init__,batch_dim=-3)\n",
    "class DropoutColwise(Dropout):\n",
    "    __init__=partialmethod(Dropout.__init__,batch_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LinearEmbedder(nn.Module):\n",
    "    def __init__(self,c_in,c_out):\n",
    "        super(LinearEmbedder,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_out=c_out\n",
    "        self.linear_1=Linear(c_in,c_out,init='relu')\n",
    "        self.relu=nn.ReLU()\n",
    "        self.linear_2=nn.Linear(c_out,c_out)\n",
    "    def forward(self,x):\n",
    "        x=self.linear_1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self,c_x,transition_n=2):\n",
    "        super(Transition,self).__init__()\n",
    "        self.LayerNorm_trans=LayerNorm(c_x)\n",
    "        self.linear_1=nn.Linear(c_x,c_x*transition_n)\n",
    "        self._elu=nn.ELU()\n",
    "        #self.linear_1=Linear(c_x,c_x*transition_n,init='relu')\n",
    "        #self._elu=nn.ReLU()\n",
    "        self.linear_2=Linear(c_x*transition_n,c_x,init='zero')\n",
    "    def forward(self,x):\n",
    "        x=self.LayerNorm_trans(x)\n",
    "        x=self.linear_1(x)\n",
    "        x=self._elu(x)\n",
    "        x=self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN=50\n",
    "def precompute_freqs_cis(dim,seq_len,theta=10000.0):\n",
    "    freqs=1.0/(theta**(torch.arange(0,dim,2)[:(dim//2)].float()/dim))\n",
    "    t=torch.arange(seq_len,device=freqs.device)\n",
    "    freqs=torch.outer(t,freqs).float()\n",
    "    freqs_cis=torch.polar(torch.ones_like(freqs),freqs)\n",
    "    return freqs_cis\n",
    "\n",
    "def apply_rotary_emb(q,k,freqs_cis,same=True):\n",
    "    _q=q.float().reshape(*q.shape[:-1],-1,2)\n",
    "    _k=k.float().reshape(*k.shape[:-1],-1,2)\n",
    "    _q=torch.view_as_complex(_q)\n",
    "    _k=torch.view_as_complex(_k)\n",
    "\n",
    "    if same==False:\n",
    "        if _k.shape[-2]%2!=0:\n",
    "            q_out=torch.view_as_real(_q*freqs_cis[int((_k.shape[-2]-1)/2)].to(q.device)).flatten(-2)\n",
    "        else:\n",
    "            q_out=torch.view_as_real(_q*freqs_cis[_k.shape[-2]/2].to(q.device)).flatten(-2)\n",
    "    else:\n",
    "        q_out=torch.view_as_real(_q*freqs_cis[:_q.shape[-2]].to(q.device)).flatten(-2)\n",
    "    k_out=torch.view_as_real(_k*freqs_cis[:_k.shape[-2]].to(k.device)).flatten(-2)\n",
    "    return q_out.type_as(q),k_out.type_as(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,c_q,c_k,c_v,c_hidden,no_heads,gating=True,use_rel_pos=False):\n",
    "        super(Attention, self).__init__()\n",
    "        self.c_q=c_q\n",
    "        self.c_k=c_k\n",
    "        self.c_v=c_v\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.gating=gating\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "\n",
    "        self.linear_q=Linear(c_q,c_hidden*no_heads,bias=False,init='glorot')\n",
    "        self.linear_k=Linear(c_k,c_hidden*no_heads,bias=False,init='glorot')\n",
    "        self.linear_v=Linear(c_v,c_hidden*no_heads,bias=False,init='glorot')\n",
    "        self.linear_o=Linear(c_hidden*no_heads,c_q,init='zero')\n",
    "        if self.gating:\n",
    "            self.linear_g=Linear(c_q,c_hidden*no_heads,init='gating')\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "        self.freqs_cis=None\n",
    "        if self.use_rel_pos:\n",
    "            self.freqs_cis=precompute_freqs_cis(c_hidden,MAX_SEQ_LEN)\n",
    "\n",
    "    def forward(self,q_x,kv_x,biases=None):\n",
    "        if(biases is None):\n",
    "            biases=[]\n",
    "        q=self.linear_q(q_x)\n",
    "        k=self.linear_k(kv_x)\n",
    "        v=self.linear_v(kv_x)\n",
    "        q=q.view(q.shape[:-1]+(self.no_heads,-1))\n",
    "        k=k.view(k.shape[:-1]+(self.no_heads,-1))\n",
    "        v=v.view(v.shape[:-1]+(self.no_heads,-1))\n",
    "\n",
    "        q=q.transpose(-2,-3)#r,H,s,h\n",
    "        k=k.transpose(-2,-3)\n",
    "        v=v.transpose(-2,-3)\n",
    "        \n",
    "        if self.use_rel_pos:\n",
    "            q,k=apply_rotary_emb(q,k,freqs_cis=self.freqs_cis,same=True)\n",
    "        k=permute_final_dims(k,(1,0))\n",
    "        a=torch.matmul(q,k)/math.sqrt(self.c_hidden)#r,H,s,h * r,H,h,s = r,H,s,s\n",
    "        for b in biases:\n",
    "            a+=b\n",
    "        a=torch.nn.functional.softmax(a,dim=-1)\n",
    "        o=torch.matmul(a,v)#r,H,s,s * r,H,s,h = r,H,s,h\n",
    "        o=o.transpose(-2,-3)#r,s,H,h\n",
    "\n",
    "        if self.gating:\n",
    "            g=self.sigmoid(self.linear_g(q_x))\n",
    "            g=g.view(g.shape[:-1]+(self.no_heads,-1))\n",
    "            o=o*g\n",
    "        o=flatten_final_dims(o,2)#r,s,H*h\n",
    "        o=self.linear_o(o)#r,s,o\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NanoAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e9,use_rel_pos=False):\n",
    "        super(NanoAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        self.layer_norm_x=LayerNorm(c_in)\n",
    "        self.mha=Attention(c_in,c_in,c_in,c_hidden,no_heads,True,use_rel_pos)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        n_seq,n_pos=x.shape[-3:-1]\n",
    "        if mask is None:\n",
    "            mask=x.new_ones(x.shape[:-3]+(n_seq,n_pos))\n",
    "        mask_bias=(self.inf*(mask-1))[...,:,None,None,:]\n",
    "        biases=[mask_bias]\n",
    "\n",
    "        x=self.layer_norm_x(x)\n",
    "        x=self.mha(x,x,biases)\n",
    "        return x\n",
    "\n",
    "class Trans_NanoAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e9,use_rel_pos=False):\n",
    "        super(Trans_NanoAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        self._NanoAttention=NanoAttention(c_in,c_hidden,no_heads,inf,use_rel_pos)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        x=x.transpose(-2,-3)\n",
    "        if mask is not None:\n",
    "            mask=mask.transpose(-1,-2)\n",
    "        x=self._NanoAttention(x,mask=mask)\n",
    "\n",
    "        x=x.transpose(-2,-3)\n",
    "        if mask is not None:\n",
    "            mask=mask.transpose(-1,-2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GlobalAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e5,eps=1e-8,use_rel_pos=False):\n",
    "        super(GlobalAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.eps=eps\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        \n",
    "        self.linear_q=Linear(c_in,c_hidden*no_heads,bias=False,init='glorot')\n",
    "        self.linear_k=Linear(c_in,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_v=Linear(c_in,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_g=Linear(c_in,c_hidden*no_heads,init='gating')\n",
    "        self.linear_o=Linear(c_hidden*no_heads,c_in,init='zero')\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.freqs_cis=None\n",
    "        if self.use_rel_pos:\n",
    "            self.freqs_cis=precompute_freqs_cis(c_hidden,MAX_SEQ_LEN)\n",
    "    def forward(self,m,mask):\n",
    "        q=torch.sum(m*mask.unsqueeze(-1),dim=-2)/(torch.sum(mask,dim=-1)[...,None]+self.eps)\n",
    "        q=self.linear_q(q)\n",
    "        k=self.linear_k(m)#r,s,h\n",
    "        v=self.linear_v(m)#r,s,h\n",
    "        q=q.view(q.shape[:-1]+(self.no_heads,-1))#r,H,h\n",
    "        if self.use_rel_pos:\n",
    "            q,k=apply_rotary_emb(q,k,freqs_cis=self.freqs_cis)\n",
    "        \n",
    "        bias=(self.inf*(mask-1))[...,:,None,:]\n",
    "        a=torch.matmul(q,k.transpose(-1,-2))/math.sqrt(self.c_hidden)#r,H,h * r,h,s = r,H,s\n",
    "        a+=bias\n",
    "        a=torch.nn.functional.softmax(a,dim=-1)\n",
    "        \n",
    "        o=torch.matmul(a,v)#r,H,s * r,s,h = r,H,h\n",
    "        g=self.sigmoid(self.linear_g(m))\n",
    "        g=g.view(g.shape[:-1]+(self.no_heads,-1))\n",
    "        o=o.unsqueeze(-3)*g#r,1,H,h * r,s,H,h = r,s,H,h\n",
    "        o=o.reshape(o.shape[:-2]+(-1,))\n",
    "        \n",
    "        m=self.linear_o(o)#r,s,H*h->r,s,c_in\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GlobalNanoAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e9,eps=1e-8,use_rel_pos=False):\n",
    "        super(GlobalNanoAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        self.layer_norm_x=LayerNorm(c_in)\n",
    "        self.gmha=GlobalAttention(c_in,c_hidden,no_heads,inf,eps,use_rel_pos)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        n_seq,n_pos=x.shape[-3:-1]\n",
    "        if mask is None:\n",
    "            mask=x.new_ones(x.shape[:-3]+(n_seq,n_pos))\n",
    "        x=self.layer_norm_x(x)\n",
    "        x=self.gmha(x,mask)\n",
    "        return x\n",
    "\n",
    "class Trans_GlobalNanoAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e9,eps=1e-8,use_rel_pos=False):\n",
    "        super(Trans_GlobalNanoAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        self._GlobalNanoAttention=GlobalNanoAttention(c_in,c_hidden,no_heads,inf,eps,use_rel_pos)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        x=x.transpose(-2,-3)\n",
    "        if mask is not None:\n",
    "            mask=mask.transpose(-1,-2)\n",
    "        x=self._GlobalNanoAttention(x,mask=mask)\n",
    "        x=x.transpose(-2,-3)\n",
    "        if mask is not None:\n",
    "            mask=mask.transpose(-1,-2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LineAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e5,eps=1e-8,use_rel_pos=False):\n",
    "        super(LineAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.eps=eps\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        \n",
    "        self.linear_q0=Linear(c_in,c_hidden*no_heads,bias=False,init='glorot')\n",
    "        self.linear_k0=Linear(c_in,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_v0=Linear(c_in,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_q1=Linear(c_hidden,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_k1=Linear(c_hidden,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_v1=Linear(c_hidden,c_hidden,bias=False,init='glorot')\n",
    "        self.linear_g=Linear(c_in,c_hidden*no_heads,init='gating')\n",
    "        self.linear_o=Linear(c_hidden*no_heads,c_in,init='zero')\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.freqs_cis=precompute_freqs_cis(c_hidden,MAX_SEQ_LEN)\n",
    "    def forward(self,m,mask):\n",
    "        l_sum=torch.sum(m*mask.unsqueeze(-1),dim=-2)/(torch.sum(mask,dim=-1)[...,None]+self.eps)\n",
    "        q0=self.linear_q0(l_sum)\n",
    "        k0=self.linear_k0(m)#r,s,h\n",
    "        v0=self.linear_v0(m)#r,s,h\n",
    "        q0=q0.view(q0.shape[:-1]+(self.no_heads,-1))#r,H,h\n",
    "        if self.use_rel_pos:\n",
    "            q0,k0=apply_rotary_emb(q0,k0,freqs_cis=self.freqs_cis,same=False)#r,H,h;r,s,h\n",
    "        bias=(self.inf*(mask-1))[...,:,None,:]\n",
    "        a0=torch.matmul(q0,k0.transpose(-1,-2))/math.sqrt(self.c_hidden)#r,H,h * r,h,s = r,H,s\n",
    "        a0+=bias\n",
    "        a0=torch.nn.functional.softmax(a0,dim=-1)\n",
    "        r0=torch.matmul(a0,v0)#r,H,s * r,s,h = r,H,h\n",
    "        \n",
    "        q1=self.linear_q1(r0)\n",
    "        k1=self.linear_q1(r0)\n",
    "        v1=self.linear_q1(r0)\n",
    "        q1=q1.transpose(-2,-3)\n",
    "        k1=k1.transpose(-2,-3)\n",
    "        v1=v1.transpose(-2,-3)\n",
    "        if not self.use_rel_pos:\n",
    "            q1,k1=apply_rotary_emb(q1,k1,freqs_cis=self.freqs_cis,same=True)#H,r,h;H,r,h\n",
    "        a1=torch.matmul(q1,k1.transpose(-1,-2))/math.sqrt(self.c_hidden)#H,r,h * H,h,r = H,r,r\n",
    "        a1=torch.nn.functional.softmax(a1,dim=-1)\n",
    "        r1=torch.matmul(a1,v1)#H,r,r * H,r,h = H,r,h\n",
    "\n",
    "        g=self.sigmoid(self.linear_g(m))\n",
    "        g=g.view(g.shape[:-1]+(self.no_heads,-1))\n",
    "        g=g.transpose(-2,-3)\n",
    "        g=g.transpose(-3,-4)\n",
    "\n",
    "        r=r1.unsqueeze(-2)*g#H,r,1,h*H,r,s,h=H,r,s,h\n",
    "        r=r.transpose(-3,-4)\n",
    "        r=r.transpose(-2,-3)\n",
    "        r=r.reshape(r.shape[:-2]+(-1,))\n",
    "        m=self.linear_o(r)#r,s,H*h->r,s,c_in\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LineNanoAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e9,eps=1e-8,use_rel_pos=False):\n",
    "        super(LineNanoAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        self.layer_norm_x=LayerNorm(c_in)\n",
    "        self.lmha=LineAttention(c_in,c_hidden,no_heads,inf,eps,use_rel_pos)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        n_seq,n_pos=x.shape[-3:-1]\n",
    "        if mask is None:\n",
    "            mask=x.new_ones(x.shape[:-3]+(n_seq,n_pos))\n",
    "        x=self.layer_norm_x(x)\n",
    "        x=self.lmha(x,mask)\n",
    "        return x\n",
    "\n",
    "class Trans_LineNanoAttention(nn.Module):\n",
    "    def __init__(self,c_in,c_hidden,no_heads,inf=1e9,eps=1e-8,use_rel_pos=False):\n",
    "        super(Trans_LineNanoAttention,self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidden=c_hidden\n",
    "        self.no_heads=no_heads\n",
    "        self.inf=inf\n",
    "        self.use_rel_pos=use_rel_pos\n",
    "        self._LineNanoAttention=LineNanoAttention(c_in,c_hidden,no_heads,inf,eps,use_rel_pos)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        x=x.transpose(-2,-3)\n",
    "        if mask is not None:\n",
    "            mask=mask.transpose(-1,-2)\n",
    "        x=self._LineNanoAttention(x,mask=mask)\n",
    "        x=x.transpose(-2,-3)\n",
    "        if mask is not None:\n",
    "            mask=mask.transpose(-1,-2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NanoBlock(nn.Module):\n",
    "    def __init__(self,c_x,c_hidden_att,no_heads,dropout,transition_n,inf,eps):\n",
    "        super(NanoBlock,self).__init__()\n",
    "        self.att_col=Trans_NanoAttention(c_x,c_hidden_att,no_heads,inf,use_rel_pos=False)\n",
    "        self.att_row=NanoAttention(c_x,c_hidden_att,no_heads,inf,use_rel_pos=True)\n",
    "        self.col_dropout_layer=DropoutColwise(dropout)\n",
    "        self.row_dropout_layer=DropoutRowwise(dropout)\n",
    "        self.transition=Transition(c_x,transition_n)\n",
    "\n",
    "    def forward(self,x,x_mask):\n",
    "        x=x+self.col_dropout_layer(self.att_col(x,x_mask).clone())\n",
    "        x=x+self.row_dropout_layer(self.att_row(x,x_mask).clone())\n",
    "        x=x+self.transition(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NanoGlobalBlock(nn.Module):\n",
    "    def __init__(self,c_x,c_hidden_att,no_heads,dropout,transition_n,inf,eps):\n",
    "        super(NanoGlobalBlock,self).__init__()\n",
    "        self.att_col=Trans_NanoAttention(c_x,c_hidden_att,no_heads,inf,use_rel_pos=False)\n",
    "        self.gatt_row=GlobalNanoAttention(c_x,c_hidden_att,no_heads,inf,eps,use_rel_pos=True)\n",
    "        self.col_dropout_layer=DropoutColwise(dropout)\n",
    "        self.row_dropout_layer=DropoutRowwise(dropout)\n",
    "        self.transition=Transition(c_x,transition_n)\n",
    "\n",
    "    def forward(self,x,x_mask):\n",
    "        x=x+self.col_dropout_layer(self.att_col(x,x_mask).clone())\n",
    "        x=x+self.row_dropout_layer(self.gatt_row(x,x_mask).clone())\n",
    "        x=x+self.transition(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NanoLineBlock(nn.Module):\n",
    "    def __init__(self,c_x,c_hidden_att,no_heads,dropout,transition_n,inf,eps):\n",
    "        super(NanoLineBlock,self).__init__()\n",
    "        self.att_col=Trans_NanoAttention(c_x,c_hidden_att,no_heads,inf,use_rel_pos=False)\n",
    "        self.latt_row=LineNanoAttention(c_x,c_hidden_att,no_heads,inf,eps,use_rel_pos=True)\n",
    "        self.col_dropout_layer=DropoutColwise(dropout)\n",
    "        self.row_dropout_layer=DropoutRowwise(dropout)\n",
    "        self.transition=Transition(c_x,transition_n)\n",
    "\n",
    "    def forward(self,x,x_mask):\n",
    "        x=x+self.col_dropout_layer(self.att_col(x,x_mask).clone())\n",
    "        x=x+self.row_dropout_layer(self.latt_row(x,x_mask).clone())\n",
    "        x=x+self.transition(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NanoStack(nn.Module):\n",
    "    def __init__(self,c_x,c_hidden_att,no_heads,blocks_lis,\n",
    "        dropout,transition_n,\n",
    "        inf,eps,clear_cache_between_blocks=False):\n",
    "        super(NanoStack,self).__init__()\n",
    "        self.clear_cache_between_blocks=clear_cache_between_blocks\n",
    "        self.blocks=nn.ModuleList()\n",
    "        for block_type in blocks_lis:\n",
    "            if block_type==0:\n",
    "                block=NanoBlock(c_x,c_hidden_att,no_heads,dropout,transition_n,inf,eps)\n",
    "            elif block_type==1:\n",
    "                block=NanoGlobalBlock(c_x,c_hidden_att,no_heads,dropout,transition_n,inf,eps)\n",
    "            elif block_type==2:\n",
    "                block=NanoLineBlock(c_x,c_hidden_att,no_heads,dropout,transition_n,inf,eps)\n",
    "            self.blocks.append(block)\n",
    "\n",
    "    def _prep_blocks(self,x_mask):\n",
    "        blocks=[partial(b,x_mask=x_mask)for b in self.blocks]\n",
    "        if(self.clear_cache_between_blocks):\n",
    "            def block_with_cache_clear(block,*args,**kwargs):\n",
    "                torch.cuda.empty_cache()\n",
    "                return block(*args,**kwargs)\n",
    "            blocks=[partial(block_with_cache_clear,b) for b in blocks]\n",
    "        return blocks\n",
    "\n",
    "    def forward(self,x,x_mask):\n",
    "        blocks=self._prep_blocks(x_mask)\n",
    "        for block in blocks:\n",
    "            x=block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Nano(nn.Module):\n",
    "    def __init__(self,c_s,c_x,c_emb,c_hidden_att,c_o,no_heads,blocks_lis,\n",
    "                dropout,transition_n,inf=1e9,eps=1e-8,clear_cache_between_blocks=False):\n",
    "        super(Nano,self).__init__()\n",
    "        self.x_embedder=LinearEmbedder(c_s+c_x,c_emb)\n",
    "        self.stack=NanoStack(c_emb,c_hidden_att,no_heads,blocks_lis,\n",
    "                     dropout,transition_n,inf,eps,clear_cache_between_blocks)\n",
    "        t_hid=int((c_emb*c_o)**0.5)\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(c_emb,t_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(t_hid,c_o),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,s,x,s_mask,x_mask):\n",
    "        s=s.unsqueeze(-3)\n",
    "        s=s.expand(*[-1]*(s.dim()-3),x.shape[-3],-1,-1)\n",
    "\n",
    "        x=torch.cat([s,x],dim=-1)\n",
    "        x=self.x_embedder(x)\n",
    "\n",
    "        x=self.stack(x,x_mask)\n",
    "        x=torch.mean(x[...,:,int(x.shape[-2]/2)+1,:],-2)\n",
    "        o=self.classifier(x).squeeze(-1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# For Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(model,test_loader,device,seq_reduce=0,read_reduce=0):\n",
    "    model.eval()\n",
    "    right_count,all_count=0,0\n",
    "    prob_all,Y_all=[],[]\n",
    "    with torch.no_grad():\n",
    "        for _,l_dic in enumerate(test_loader):\n",
    "            l_dic={k:v.to(device) for k, v in l_dic.items()}\n",
    "            data_y=l_dic['label'].to(torch.int64)\n",
    "            if seq_reduce==0:\n",
    "                seq_feature=l_dic['seq_feature']\n",
    "                seq_mask=l_dic['seq_mask']\n",
    "                nano_feature=l_dic['nano_feature'][:,read_reduce:]\n",
    "                nano_mask=l_dic['nano_mask'][:,read_reduce:]\n",
    "            else:\n",
    "                side_reduce=int(seq_reduce/2)\n",
    "                seq_feature=l_dic['seq_feature'][:,side_reduce:-side_reduce]\n",
    "                seq_mask=l_dic['seq_mask'][:,side_reduce:-side_reduce]\n",
    "                nano_feature=l_dic['nano_feature'][:,read_reduce:,side_reduce:-side_reduce]\n",
    "                nano_mask=l_dic['nano_mask'][:,read_reduce:,side_reduce:-side_reduce]\n",
    "            pre_y=model(seq_feature,nano_feature,seq_mask,nano_mask)\n",
    "            out_y=pre_y>0.5\n",
    "            right_count+=out_y.eq(data_y).sum()\n",
    "            all_count+=len(data_y)\n",
    "            for each in pre_y:\n",
    "                prob_all.append(np.array(each.cpu()))\n",
    "            for each in data_y:\n",
    "                Y_all.append(np.array(each.cpu()))\n",
    "    roauc=roc_auc_score(Y_all,prob_all)\n",
    "\n",
    "    accuracy=100*(right_count/all_count).item()\n",
    "    print('AUC:{:.4f}, accuracy:{:.4f}%'.format(roauc,accuracy))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def train(model,train_loader,val_loader,device,optimizer,loss_func,epochs,seq_reduce=0,read_reduce=0):\n",
    "    torch.cuda.empty_cache()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss=0\n",
    "        model.train()\n",
    "        for _,l_dic in enumerate(train_loader):\n",
    "            l_dic={k:v.to(device) for k, v in l_dic.items()}\n",
    "            data_y=l_dic['label']\n",
    "            if seq_reduce==0:\n",
    "                seq_feature=l_dic['seq_feature']\n",
    "                seq_mask=l_dic['seq_mask']\n",
    "                nano_feature=l_dic['nano_feature'][:,read_reduce:]\n",
    "                nano_mask=l_dic['nano_mask'][:,read_reduce:]\n",
    "            else:\n",
    "                side_reduce=int(seq_reduce/2)\n",
    "                seq_feature=l_dic['seq_feature'][:,side_reduce:-side_reduce]\n",
    "                seq_mask=l_dic['seq_mask'][:,side_reduce:-side_reduce]\n",
    "                nano_feature=l_dic['nano_feature'][:,read_reduce:,side_reduce:-side_reduce]\n",
    "                nano_mask=l_dic['nano_mask'][:,read_reduce:,side_reduce:-side_reduce]\n",
    "            pre_y=model(seq_feature,nano_feature,seq_mask,nano_mask)\n",
    "            loss=loss_func(pre_y,data_y.float())\n",
    "            total_loss+=loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('epoch {}, loss:{:.4f}'.format(epoch+1,total_loss.item()/len(train_loader)))\n",
    "        if epoch%10==9:\n",
    "            print('At epoch '+str(epoch+1),':')\n",
    "            test(model,val_loader,device,seq_reduce,read_reduce)\n",
    "            torch.save(model.state_dict(),'./model/model_'+str(epoch+1)+'_'+str(int(time.time()))+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detailed_test(model,test_loader,device,seq_reduce=0,read_reduce=0,curve_name=None,histo_name=None):\n",
    "    model.eval()\n",
    "    right_count,all_count=0,0\n",
    "    more_dict={0.5:[0,0],0.6:[0,0],0.8:[0,0],0.7:[0,0],0.9:[0,0],0.95:[0,0],0.98:[0,0],\\\n",
    "               0.99:[0,0],0.995:[0,0],0.999:[0,0],0.9995:[0,0],0.9999:[0,0],0.99995:[0,0],\\\n",
    "               0.99999:[0,0],0.999995:[0,0],0.999999:[0,0]}\n",
    "    prob_all,Y_all=[],[]\n",
    "    motif_dict={}\n",
    "    range_list=[]\n",
    "    with torch.no_grad():\n",
    "        for _,l_dic in enumerate(test_loader):\n",
    "            l_dic={k:v.to(device) for k, v in l_dic.items()}\n",
    "            data_y=l_dic['label'].to(torch.int64)\n",
    "            if seq_reduce==0:\n",
    "                seq_feature=l_dic['seq_feature']\n",
    "                seq_mask=l_dic['seq_mask']\n",
    "                nano_feature=l_dic['nano_feature'][:,read_reduce:]\n",
    "                nano_mask=l_dic['nano_mask'][:,read_reduce:]\n",
    "            else:\n",
    "                side_reduce=int(seq_reduce/2)\n",
    "                seq_feature=l_dic['seq_feature'][:,side_reduce:-side_reduce]\n",
    "                seq_mask=l_dic['seq_mask'][:,side_reduce:-side_reduce]\n",
    "                nano_feature=l_dic['nano_feature'][:,read_reduce:,side_reduce:-side_reduce]\n",
    "                nano_mask=l_dic['nano_mask'][:,read_reduce:,side_reduce:-side_reduce]\n",
    "            pre_y=model(seq_feature,nano_feature,seq_mask,nano_mask)\n",
    "            out_y=pre_y>0.5\n",
    "            right_count+=out_y.eq(data_y).sum()\n",
    "            all_count+=len(data_y)\n",
    "            for each in pre_y:\n",
    "                prob_all.append(np.array(each.cpu()))\n",
    "            for each in data_y:\n",
    "                Y_all.append(np.array(each.cpu()))\n",
    "            for key in more_dict:\n",
    "                more_dict[key][0]+=((pre_y>key)&data_y).sum()\n",
    "                more_dict[key][1]+=(pre_y>key).sum()\n",
    "\n",
    "            if histo_name:\n",
    "                middle_pos=int((len(l_dic['seq_feature'][0])-1)/2)\n",
    "                center_seqs=l_dic['seq_feature'][:,middle_pos-2:middle_pos+3]            \n",
    "                for i in range(len(data_y)):\n",
    "                    _Seq=''\n",
    "                    for j in range(5):\n",
    "                        if abs(center_seqs[i][j][0]-1)<0.01:\n",
    "                            _Seq+='A'\n",
    "                        elif abs(center_seqs[i][j][1]-1)<0.01:\n",
    "                            _Seq+='T'\n",
    "                        elif abs(center_seqs[i][j][2]-1)<0.01:\n",
    "                            _Seq+='C'\n",
    "                        elif abs(center_seqs[i][j][3]-1)<0.01:\n",
    "                            _Seq+='G'\n",
    "                        else:\n",
    "                            _Seq+='N'\n",
    "                    if 'N' not in _Seq:\n",
    "                        if _Seq not in motif_dict:\n",
    "                            motif_dict[_Seq]={'TP':0,'FP':0,'TN':0,'FN':0}\n",
    "                        if out_y[i]==1 and data_y[i]==1:\n",
    "                            motif_dict[_Seq]['TP']+=1\n",
    "                        elif out_y[i]==1 and data_y[i]==0:\n",
    "                            motif_dict[_Seq]['FP']+=1\n",
    "                        elif out_y[i]==0 and data_y[i]==0:\n",
    "                            motif_dict[_Seq]['TN']+=1\n",
    "                        elif out_y[i]==0 and data_y[i]==1:\n",
    "                            motif_dict[_Seq]['FN']+=1\n",
    "                for i in range(len(pre_y)):\n",
    "                    range_list.append([pre_y[i].cpu().item(),data_y[i].cpu().item()])\n",
    "    if histo_name:\n",
    "        save_frame=pd.DataFrame(motif_dict).T\n",
    "        save_frame.to_csv('./edata/Save_for_drawing/'+histo_name+'_motif_histo.csv',index=True,sep=',')\n",
    "        save_frame=pd.DataFrame(range_list)\n",
    "        save_frame.columns=['Probability score','Ground Truth']\n",
    "        save_frame.to_csv('./edata/Save_for_drawing/'+histo_name+'_range_histo.csv',index=False,sep=',')\n",
    "    if curve_name:\n",
    "        save_frame=pd.DataFrame({'label':Y_all,'pred':prob_all})\n",
    "        save_frame.to_csv('./edata/Save_for_drawing/'+curve_name+'_curve.csv',index=False,sep=',')\n",
    "\n",
    "    print('Im total',all_count,'samples:')\n",
    "    auc=roc_auc_score(Y_all,prob_all)\n",
    "    accuracy=100*(right_count/all_count).item()\n",
    "    print('AUC:{:.4f}   accuracy:{:.4f}%'.format(auc,accuracy))\n",
    "    for key in more_dict:\n",
    "        if more_dict[key][1]>0:\n",
    "            print('Precision when positive threshold at {:g} is :{:.4f}% (total:{:d})'.format(key,100*(more_dict[key][0]/more_dict[key][1]),more_dict[key][1]))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are chances that loss won't decline, re-run would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss:0.7072\n",
      "epoch 2, loss:0.6831\n",
      "epoch 3, loss:0.6667\n",
      "epoch 4, loss:0.6559\n",
      "epoch 5, loss:0.6507\n",
      "epoch 6, loss:0.6463\n",
      "epoch 7, loss:0.6433\n",
      "epoch 8, loss:0.6394\n",
      "epoch 9, loss:0.6271\n",
      "epoch 10, loss:0.6310\n",
      "At epoch 10 :\n",
      "AUC:0.7119, accuracy:66.4587%\n",
      "epoch 11, loss:0.6187\n",
      "epoch 12, loss:0.6113\n",
      "epoch 13, loss:0.5966\n",
      "epoch 14, loss:0.5858\n",
      "epoch 15, loss:0.5783\n",
      "epoch 16, loss:0.5823\n",
      "epoch 17, loss:0.5695\n",
      "epoch 18, loss:0.5712\n",
      "epoch 19, loss:0.5630\n",
      "epoch 20, loss:0.5605\n",
      "At epoch 20 :\n",
      "AUC:0.7458, accuracy:67.5507%\n",
      "epoch 21, loss:0.5526\n",
      "epoch 22, loss:0.5461\n",
      "epoch 23, loss:0.5360\n",
      "epoch 24, loss:0.5288\n",
      "epoch 25, loss:0.5244\n",
      "epoch 26, loss:0.5068\n",
      "epoch 27, loss:0.5052\n",
      "epoch 28, loss:0.4982\n",
      "epoch 29, loss:0.4856\n",
      "epoch 30, loss:0.4798\n",
      "At epoch 30 :\n",
      "AUC:0.8023, accuracy:72.4649%\n",
      "epoch 31, loss:0.4676\n",
      "epoch 32, loss:0.4607\n",
      "epoch 33, loss:0.4535\n",
      "epoch 34, loss:0.4456\n",
      "epoch 35, loss:0.4373\n",
      "epoch 36, loss:0.4331\n",
      "epoch 37, loss:0.4226\n",
      "epoch 38, loss:0.4150\n",
      "epoch 39, loss:0.4135\n",
      "epoch 40, loss:0.4077\n",
      "At epoch 40 :\n",
      "AUC:0.8133, accuracy:75.3510%\n",
      "epoch 41, loss:0.4092\n",
      "epoch 42, loss:0.3977\n",
      "epoch 43, loss:0.3889\n",
      "epoch 44, loss:0.3861\n",
      "epoch 45, loss:0.3772\n",
      "epoch 46, loss:0.3771\n",
      "epoch 47, loss:0.3636\n",
      "epoch 48, loss:0.3639\n",
      "epoch 49, loss:0.3537\n",
      "epoch 50, loss:0.3609\n",
      "At epoch 50 :\n",
      "AUC:0.8349, accuracy:74.1810%\n",
      "epoch 51, loss:0.3426\n",
      "epoch 52, loss:0.3477\n",
      "epoch 53, loss:0.3368\n",
      "epoch 54, loss:0.3376\n",
      "epoch 55, loss:0.3342\n",
      "epoch 56, loss:0.3256\n",
      "epoch 57, loss:0.3220\n",
      "epoch 58, loss:0.3145\n",
      "epoch 59, loss:0.3163\n",
      "epoch 60, loss:0.3232\n",
      "At epoch 60 :\n",
      "AUC:0.8141, accuracy:72.9329%\n",
      "epoch 61, loss:0.3087\n",
      "epoch 62, loss:0.2987\n",
      "epoch 63, loss:0.2896\n",
      "epoch 64, loss:0.3053\n",
      "epoch 65, loss:0.2889\n",
      "epoch 66, loss:0.2854\n",
      "epoch 67, loss:0.2746\n",
      "epoch 68, loss:0.2794\n",
      "epoch 69, loss:0.2749\n",
      "epoch 70, loss:0.2698\n",
      "At epoch 70 :\n",
      "AUC:0.8133, accuracy:73.6349%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed_all(0)\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_func=nn.BCELoss()\n",
    "epochs=70\n",
    "train(model,train_loader,val_loader,device,optimizer,loss_func,epochs,seq_reduce=16,read_reduce=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss:0.7023\n",
      "epoch 2, loss:0.6858\n",
      "epoch 3, loss:0.6698\n",
      "epoch 4, loss:0.6547\n",
      "epoch 5, loss:0.6498\n",
      "epoch 6, loss:0.6434\n",
      "epoch 7, loss:0.6388\n",
      "epoch 8, loss:0.6408\n",
      "epoch 9, loss:0.6342\n",
      "epoch 10, loss:0.6319\n",
      "At epoch 10 :\n",
      "AUC:0.6870, accuracy:62.0125%\n",
      "epoch 11, loss:0.6285\n",
      "epoch 12, loss:0.6278\n",
      "epoch 13, loss:0.6178\n",
      "epoch 14, loss:0.6089\n",
      "epoch 15, loss:0.5985\n",
      "epoch 16, loss:0.5911\n",
      "epoch 17, loss:0.5775\n",
      "epoch 18, loss:0.5747\n",
      "epoch 19, loss:0.5719\n",
      "epoch 20, loss:0.5573\n",
      "At epoch 20 :\n",
      "AUC:0.7622, accuracy:67.5507%\n",
      "epoch 21, loss:0.5420\n",
      "epoch 22, loss:0.5367\n",
      "epoch 23, loss:0.5203\n",
      "epoch 24, loss:0.5175\n",
      "epoch 25, loss:0.5076\n",
      "epoch 26, loss:0.5032\n",
      "epoch 27, loss:0.4972\n",
      "epoch 28, loss:0.4907\n",
      "epoch 29, loss:0.4797\n",
      "epoch 30, loss:0.4690\n",
      "At epoch 30 :\n",
      "AUC:0.8229, accuracy:75.9750%\n",
      "epoch 31, loss:0.4753\n",
      "epoch 32, loss:0.4708\n",
      "epoch 33, loss:0.4686\n",
      "epoch 34, loss:0.4669\n",
      "epoch 35, loss:0.4521\n",
      "epoch 36, loss:0.4557\n",
      "epoch 37, loss:0.4474\n",
      "epoch 38, loss:0.4403\n",
      "epoch 39, loss:0.4475\n",
      "epoch 40, loss:0.4444\n",
      "At epoch 40 :\n",
      "AUC:0.8120, accuracy:74.8050%\n",
      "epoch 41, loss:0.4340\n",
      "epoch 42, loss:0.4296\n",
      "epoch 43, loss:0.4299\n",
      "epoch 44, loss:0.4325\n",
      "epoch 45, loss:0.4175\n",
      "epoch 46, loss:0.4242\n",
      "epoch 47, loss:0.4199\n",
      "epoch 48, loss:0.4203\n",
      "epoch 49, loss:0.4223\n",
      "epoch 50, loss:0.4063\n",
      "At epoch 50 :\n",
      "AUC:0.8160, accuracy:72.5429%\n",
      "epoch 51, loss:0.4070\n",
      "epoch 52, loss:0.3974\n",
      "epoch 53, loss:0.3983\n",
      "epoch 54, loss:0.3945\n",
      "epoch 55, loss:0.3959\n",
      "epoch 56, loss:0.3851\n",
      "epoch 57, loss:0.3777\n",
      "epoch 58, loss:0.3798\n",
      "epoch 59, loss:0.3860\n",
      "epoch 60, loss:0.3861\n",
      "At epoch 60 :\n",
      "AUC:0.8179, accuracy:74.9610%\n",
      "epoch 61, loss:0.3726\n",
      "epoch 62, loss:0.3746\n",
      "epoch 63, loss:0.3656\n",
      "epoch 64, loss:0.3630\n",
      "epoch 65, loss:0.3735\n",
      "epoch 66, loss:0.3623\n",
      "epoch 67, loss:0.3643\n",
      "epoch 68, loss:0.3517\n",
      "epoch 69, loss:0.3550\n",
      "epoch 70, loss:0.3484\n",
      "At epoch 70 :\n",
      "AUC:0.7926, accuracy:73.0109%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed_all(0)\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[0,0,0,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_func=nn.BCELoss()\n",
    "epochs=70\n",
    "train(model,train_loader,val_loader,device,optimizer,loss_func,epochs,seq_reduce=16,read_reduce=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :Erroneous % when print precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 1298 samples:\n",
      "AUC:0.8416   accuracy:76.6564%\n",
      "Precision when positive threshold at 0.5 is :84.4068% (total:590)\n",
      "Precision when positive threshold at 0.6 is :85.5787% (total:527)\n",
      "Precision when positive threshold at 0.8 is :89.6254% (total:347)\n",
      "Precision when positive threshold at 0.7 is :87.6623% (total:462)\n",
      "Precision when positive threshold at 0.9 is :95.0276% (total:181)\n",
      "Precision when positive threshold at 0.95 is :96.2500% (total:80)\n",
      "Precision when positive threshold at 0.98 is :96.8750% (total:32)\n",
      "Precision when positive threshold at 0.99 is :100.0000% (total:19)\n",
      "Precision when positive threshold at 0.995 is :100.0000% (total:8)\n",
      "Precision when positive threshold at 0.999 is :100.0000% (total:2)\n",
      "Precision when positive threshold at 0.9995 is :100.0000% (total:2)\n"
     ]
    }
   ],
   "source": [
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_222000_50_50reads_9sites.pkl',weights_only=True))\n",
    "detailed_test(model,test_loader,device,seq_reduce=16,read_reduce=0,\\\n",
    "              curve_name='Blocks=[222000],50reads_9sites',histo_name='Blocks=[222000],50reads_9sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 1298 samples:\n",
      "AUC:0.8435   accuracy:78.8136%\n",
      "Precision when positive threshold at 0.5 is :78.7037% (total:756)\n",
      "Precision when positive threshold at 0.6 is :79.9151% (total:707)\n",
      "Precision when positive threshold at 0.8 is :84.3173% (total:542)\n",
      "Precision when positive threshold at 0.7 is :81.9149% (total:658)\n",
      "Precision when positive threshold at 0.9 is :88.8252% (total:349)\n",
      "Precision when positive threshold at 0.95 is :88.7179% (total:195)\n",
      "Precision when positive threshold at 0.98 is :94.8052% (total:77)\n",
      "Precision when positive threshold at 0.99 is :93.5484% (total:31)\n",
      "Precision when positive threshold at 0.995 is :100.0000% (total:13)\n",
      "Precision when positive threshold at 0.999 is :100.0000% (total:4)\n",
      "Precision when positive threshold at 0.9995 is :100.0000% (total:3)\n",
      "Precision when positive threshold at 0.9999 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.99995 is :100.0000% (total:1)\n"
     ]
    }
   ],
   "source": [
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[0,0,0,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_000000_30_50reads_9sites.pkl',weights_only=True))\n",
    "detailed_test(model,test_loader,device,seq_reduce=16,read_reduce=0,\\\n",
    "              curve_name='Blocks=[000000],50reads_9sites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extra training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss:0.7702\n",
      "epoch 2, loss:0.6955\n",
      "epoch 3, loss:0.6733\n",
      "epoch 4, loss:0.6635\n",
      "epoch 5, loss:0.6609\n",
      "epoch 6, loss:0.6598\n",
      "epoch 7, loss:0.6576\n",
      "epoch 8, loss:0.6630\n",
      "epoch 9, loss:0.6549\n",
      "epoch 10, loss:0.6521\n",
      "At epoch 10 :\n",
      "AUC:0.6660, accuracy:62.4037%\n",
      "epoch 11, loss:0.6515\n",
      "epoch 12, loss:0.6482\n",
      "epoch 13, loss:0.6478\n",
      "epoch 14, loss:0.6425\n",
      "epoch 15, loss:0.6415\n",
      "epoch 16, loss:0.6374\n",
      "epoch 17, loss:0.6356\n",
      "epoch 18, loss:0.6334\n",
      "epoch 19, loss:0.6335\n",
      "epoch 20, loss:0.6287\n",
      "At epoch 20 :\n",
      "AUC:0.6880, accuracy:63.1741%\n",
      "epoch 21, loss:0.6308\n",
      "epoch 22, loss:0.6279\n",
      "epoch 23, loss:0.6227\n",
      "epoch 24, loss:0.6245\n",
      "epoch 25, loss:0.6212\n",
      "epoch 26, loss:0.6207\n",
      "epoch 27, loss:0.6165\n",
      "epoch 28, loss:0.6135\n",
      "epoch 29, loss:0.6139\n",
      "epoch 30, loss:0.6026\n",
      "At epoch 30 :\n",
      "AUC:0.7145, accuracy:66.5639%\n",
      "epoch 31, loss:0.6040\n",
      "epoch 32, loss:0.6000\n",
      "epoch 33, loss:0.5945\n",
      "epoch 34, loss:0.5873\n",
      "epoch 35, loss:0.5801\n",
      "epoch 36, loss:0.5800\n",
      "epoch 37, loss:0.5759\n",
      "epoch 38, loss:0.5656\n",
      "epoch 39, loss:0.5656\n",
      "epoch 40, loss:0.5537\n",
      "At epoch 40 :\n",
      "AUC:0.7449, accuracy:67.1803%\n",
      "epoch 41, loss:0.5545\n",
      "epoch 42, loss:0.5486\n",
      "epoch 43, loss:0.5445\n",
      "epoch 44, loss:0.5302\n",
      "epoch 45, loss:0.5340\n",
      "epoch 46, loss:0.5426\n",
      "epoch 47, loss:0.5241\n",
      "epoch 48, loss:0.5287\n",
      "epoch 49, loss:0.5213\n",
      "epoch 50, loss:0.5175\n",
      "At epoch 50 :\n",
      "AUC:0.7899, accuracy:72.0339%\n",
      "epoch 51, loss:0.5044\n",
      "epoch 52, loss:0.4962\n",
      "epoch 53, loss:0.4964\n",
      "epoch 54, loss:0.4866\n",
      "epoch 55, loss:0.4881\n",
      "epoch 56, loss:0.4839\n",
      "epoch 57, loss:0.4757\n",
      "epoch 58, loss:0.4799\n",
      "epoch 59, loss:0.4753\n",
      "epoch 60, loss:0.4645\n",
      "At epoch 60 :\n",
      "AUC:0.8168, accuracy:74.7304%\n",
      "epoch 61, loss:0.4587\n",
      "epoch 62, loss:0.4487\n",
      "epoch 63, loss:0.4525\n",
      "epoch 64, loss:0.4500\n",
      "epoch 65, loss:0.4381\n",
      "epoch 66, loss:0.4341\n",
      "epoch 67, loss:0.4361\n",
      "epoch 68, loss:0.4290\n",
      "epoch 69, loss:0.4339\n",
      "epoch 70, loss:0.4236\n",
      "At epoch 70 :\n",
      "AUC:0.8039, accuracy:72.1109%\n",
      "epoch 71, loss:0.4044\n",
      "epoch 72, loss:0.4034\n",
      "epoch 73, loss:0.4077\n",
      "epoch 74, loss:0.4110\n",
      "epoch 75, loss:0.3936\n",
      "epoch 76, loss:0.4053\n",
      "epoch 77, loss:0.3822\n",
      "epoch 78, loss:0.3937\n",
      "epoch 79, loss:0.3918\n",
      "epoch 80, loss:0.3930\n",
      "At epoch 80 :\n",
      "AUC:0.8166, accuracy:73.8829%\n",
      "epoch 81, loss:0.3874\n",
      "epoch 82, loss:0.3834\n",
      "epoch 83, loss:0.3726\n",
      "epoch 84, loss:0.3696\n",
      "epoch 85, loss:0.3531\n",
      "epoch 86, loss:0.3776\n",
      "epoch 87, loss:0.3561\n",
      "epoch 88, loss:0.3485\n",
      "epoch 89, loss:0.3441\n",
      "epoch 90, loss:0.3702\n",
      "At epoch 90 :\n",
      "AUC:0.7598, accuracy:70.1849%\n",
      "epoch 91, loss:0.3973\n",
      "epoch 92, loss:0.3517\n",
      "epoch 93, loss:0.3412\n",
      "epoch 94, loss:0.3279\n",
      "epoch 95, loss:0.3456\n",
      "epoch 96, loss:0.3260\n",
      "epoch 97, loss:0.3341\n",
      "epoch 98, loss:0.3127\n",
      "epoch 99, loss:0.3292\n",
      "epoch 100, loss:0.3078\n",
      "At epoch 100 :\n",
      "AUC:0.7747, accuracy:69.9538%\n",
      "epoch 101, loss:0.3071\n",
      "epoch 102, loss:0.3167\n",
      "epoch 103, loss:0.3044\n",
      "epoch 104, loss:0.3129\n",
      "epoch 105, loss:0.2992\n",
      "epoch 106, loss:0.3009\n",
      "epoch 107, loss:0.2996\n",
      "epoch 108, loss:0.2957\n",
      "epoch 109, loss:0.3037\n",
      "epoch 110, loss:0.2963\n",
      "At epoch 110 :\n",
      "AUC:0.7894, accuracy:71.6487%\n",
      "epoch 111, loss:0.2956\n",
      "epoch 112, loss:0.2931\n",
      "epoch 113, loss:0.2946\n",
      "epoch 114, loss:0.2725\n",
      "epoch 115, loss:0.2800\n",
      "epoch 116, loss:0.2626\n",
      "epoch 117, loss:0.2789\n",
      "epoch 118, loss:0.2747\n",
      "epoch 119, loss:0.2722\n",
      "epoch 120, loss:0.2579\n",
      "At epoch 120 :\n",
      "AUC:0.7967, accuracy:72.5732%\n",
      "epoch 121, loss:0.2581\n",
      "epoch 122, loss:0.2720\n",
      "epoch 123, loss:0.2595\n",
      "epoch 124, loss:0.2518\n",
      "epoch 125, loss:0.2621\n",
      "epoch 126, loss:0.2555\n",
      "epoch 127, loss:0.2421\n",
      "epoch 128, loss:0.2642\n",
      "epoch 129, loss:0.2597\n",
      "epoch 130, loss:0.2401\n",
      "At epoch 130 :\n",
      "AUC:0.7928, accuracy:72.6502%\n",
      "epoch 131, loss:0.2465\n",
      "epoch 132, loss:0.2453\n",
      "epoch 133, loss:0.2391\n",
      "epoch 134, loss:0.2462\n",
      "epoch 135, loss:0.2364\n",
      "epoch 136, loss:0.2495\n",
      "epoch 137, loss:0.2279\n",
      "epoch 138, loss:0.2350\n",
      "epoch 139, loss:0.2268\n",
      "epoch 140, loss:0.2335\n",
      "At epoch 140 :\n",
      "AUC:0.7886, accuracy:72.2650%\n",
      "epoch 141, loss:0.2139\n",
      "epoch 142, loss:0.2287\n",
      "epoch 143, loss:0.2149\n",
      "epoch 144, loss:0.2241\n",
      "epoch 145, loss:0.2125\n",
      "epoch 146, loss:0.2198\n",
      "epoch 147, loss:0.2308\n",
      "epoch 148, loss:0.2101\n",
      "epoch 149, loss:0.2148\n",
      "epoch 150, loss:0.2179\n",
      "At epoch 150 :\n",
      "AUC:0.7886, accuracy:71.8028%\n"
     ]
    }
   ],
   "source": [
    "#use only 20 reads\n",
    "torch.cuda.manual_seed_all(0)\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_func=nn.BCELoss()\n",
    "epochs=150\n",
    "train(model,train_loader,test_loader,device,optimizer,loss_func,epochs,seq_reduce=16,read_reduce=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss:0.6989\n",
      "epoch 2, loss:0.6771\n",
      "epoch 3, loss:0.6622\n",
      "epoch 4, loss:0.6536\n",
      "epoch 5, loss:0.6449\n",
      "epoch 6, loss:0.6417\n",
      "epoch 7, loss:0.6333\n",
      "epoch 8, loss:0.6321\n",
      "epoch 9, loss:0.6296\n",
      "epoch 10, loss:0.6200\n",
      "At epoch 10 :\n",
      "AUC:0.7041, accuracy:64.5609%\n",
      "epoch 11, loss:0.6131\n",
      "epoch 12, loss:0.6138\n",
      "epoch 13, loss:0.6063\n",
      "epoch 14, loss:0.6005\n",
      "epoch 15, loss:0.5962\n",
      "epoch 16, loss:0.5904\n",
      "epoch 17, loss:0.5861\n",
      "epoch 18, loss:0.5771\n",
      "epoch 19, loss:0.5656\n",
      "epoch 20, loss:0.5558\n",
      "At epoch 20 :\n",
      "AUC:0.7315, accuracy:62.2496%\n",
      "epoch 21, loss:0.5564\n",
      "epoch 22, loss:0.5423\n",
      "epoch 23, loss:0.5328\n",
      "epoch 24, loss:0.5338\n",
      "epoch 25, loss:0.5209\n",
      "epoch 26, loss:0.5135\n",
      "epoch 27, loss:0.5024\n",
      "epoch 28, loss:0.4877\n",
      "epoch 29, loss:0.4820\n",
      "epoch 30, loss:0.4735\n",
      "At epoch 30 :\n",
      "AUC:0.7513, accuracy:69.5686%\n",
      "epoch 31, loss:0.4597\n",
      "epoch 32, loss:0.4564\n",
      "epoch 33, loss:0.4517\n",
      "epoch 34, loss:0.4322\n",
      "epoch 35, loss:0.4302\n",
      "epoch 36, loss:0.4177\n",
      "epoch 37, loss:0.4096\n",
      "epoch 38, loss:0.3969\n",
      "epoch 39, loss:0.3864\n",
      "epoch 40, loss:0.3845\n",
      "At epoch 40 :\n",
      "AUC:0.7489, accuracy:67.6425%\n",
      "epoch 41, loss:0.3800\n",
      "epoch 42, loss:0.3826\n",
      "epoch 43, loss:0.3600\n",
      "epoch 44, loss:0.3559\n",
      "epoch 45, loss:0.3546\n",
      "epoch 46, loss:0.3337\n",
      "epoch 47, loss:0.3293\n",
      "epoch 48, loss:0.3327\n",
      "epoch 49, loss:0.3129\n",
      "epoch 50, loss:0.3118\n",
      "At epoch 50 :\n",
      "AUC:0.7772, accuracy:71.0324%\n",
      "epoch 51, loss:0.3030\n",
      "epoch 52, loss:0.2910\n",
      "epoch 53, loss:0.2995\n",
      "epoch 54, loss:0.2915\n",
      "epoch 55, loss:0.2836\n",
      "epoch 56, loss:0.2620\n",
      "epoch 57, loss:0.2683\n",
      "epoch 58, loss:0.2664\n",
      "epoch 59, loss:0.2677\n",
      "epoch 60, loss:0.2408\n",
      "At epoch 60 :\n",
      "AUC:0.7691, accuracy:69.7997%\n",
      "epoch 61, loss:0.2456\n",
      "epoch 62, loss:0.2315\n",
      "epoch 63, loss:0.2400\n",
      "epoch 64, loss:0.2395\n",
      "epoch 65, loss:0.2208\n",
      "epoch 66, loss:0.2286\n",
      "epoch 67, loss:0.2375\n",
      "epoch 68, loss:0.2130\n",
      "epoch 69, loss:0.1996\n",
      "epoch 70, loss:0.2207\n",
      "At epoch 70 :\n",
      "AUC:0.7793, accuracy:70.4160%\n",
      "epoch 71, loss:0.1931\n",
      "epoch 72, loss:0.1921\n",
      "epoch 73, loss:0.1835\n",
      "epoch 74, loss:0.1850\n",
      "epoch 75, loss:0.1821\n",
      "epoch 76, loss:0.1760\n",
      "epoch 77, loss:0.1812\n",
      "epoch 78, loss:0.1655\n",
      "epoch 79, loss:0.2043\n",
      "epoch 80, loss:0.1655\n",
      "At epoch 80 :\n",
      "AUC:0.7571, accuracy:68.8752%\n",
      "epoch 81, loss:0.1673\n",
      "epoch 82, loss:0.1759\n",
      "epoch 83, loss:0.1692\n",
      "epoch 84, loss:0.1584\n",
      "epoch 85, loss:0.1526\n",
      "epoch 86, loss:0.1506\n",
      "epoch 87, loss:0.1339\n",
      "epoch 88, loss:0.1626\n",
      "epoch 89, loss:0.1583\n",
      "epoch 90, loss:0.1535\n",
      "At epoch 90 :\n",
      "AUC:0.7623, accuracy:69.5686%\n",
      "epoch 91, loss:0.1418\n",
      "epoch 92, loss:0.1373\n",
      "epoch 93, loss:0.1311\n",
      "epoch 94, loss:0.1330\n",
      "epoch 95, loss:0.1414\n",
      "epoch 96, loss:0.1312\n",
      "epoch 97, loss:0.1310\n",
      "epoch 98, loss:0.1328\n",
      "epoch 99, loss:0.1374\n",
      "epoch 100, loss:0.1162\n",
      "At epoch 100 :\n",
      "AUC:0.7514, accuracy:68.1048%\n",
      "epoch 101, loss:0.1337\n",
      "epoch 102, loss:0.1185\n",
      "epoch 103, loss:0.1240\n",
      "epoch 104, loss:0.1062\n",
      "epoch 105, loss:0.1297\n",
      "epoch 106, loss:0.1120\n",
      "epoch 107, loss:0.0982\n",
      "epoch 108, loss:0.1141\n",
      "epoch 109, loss:0.1195\n",
      "epoch 110, loss:0.0963\n",
      "At epoch 110 :\n",
      "AUC:0.7887, accuracy:71.1864%\n",
      "epoch 111, loss:0.1186\n",
      "epoch 112, loss:0.0993\n",
      "epoch 113, loss:0.1038\n",
      "epoch 114, loss:0.1027\n",
      "epoch 115, loss:0.1037\n",
      "epoch 116, loss:0.0933\n",
      "epoch 117, loss:0.1009\n",
      "epoch 118, loss:0.0984\n",
      "epoch 119, loss:0.1044\n",
      "epoch 120, loss:0.0990\n",
      "At epoch 120 :\n",
      "AUC:0.7629, accuracy:68.8752%\n",
      "epoch 121, loss:0.0931\n",
      "epoch 122, loss:0.0875\n",
      "epoch 123, loss:0.0960\n",
      "epoch 124, loss:0.0920\n",
      "epoch 125, loss:0.1023\n",
      "epoch 126, loss:0.0936\n",
      "epoch 127, loss:0.0898\n",
      "epoch 128, loss:0.0798\n",
      "epoch 129, loss:0.0936\n",
      "epoch 130, loss:0.0892\n",
      "At epoch 130 :\n",
      "AUC:0.7661, accuracy:70.6472%\n",
      "epoch 131, loss:0.0796\n",
      "epoch 132, loss:0.0908\n",
      "epoch 133, loss:0.0901\n",
      "epoch 134, loss:0.0866\n",
      "epoch 135, loss:0.0804\n",
      "epoch 136, loss:0.0914\n",
      "epoch 137, loss:0.0816\n",
      "epoch 138, loss:0.0766\n",
      "epoch 139, loss:0.0808\n",
      "epoch 140, loss:0.0709\n",
      "At epoch 140 :\n",
      "AUC:0.7510, accuracy:67.1803%\n",
      "epoch 141, loss:0.0879\n",
      "epoch 142, loss:0.0806\n",
      "epoch 143, loss:0.0746\n",
      "epoch 144, loss:0.0772\n",
      "epoch 145, loss:0.0917\n",
      "epoch 146, loss:0.0749\n",
      "epoch 147, loss:0.0714\n",
      "epoch 148, loss:0.0804\n",
      "epoch 149, loss:0.0829\n",
      "epoch 150, loss:0.0719\n",
      "At epoch 150 :\n",
      "AUC:0.7491, accuracy:68.5670%\n"
     ]
    }
   ],
   "source": [
    "#use all 25 sites\n",
    "torch.cuda.manual_seed_all(0)\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_func=nn.BCELoss()\n",
    "epochs=150\n",
    "train(model,train_loader,test_loader,device,optimizer,loss_func,epochs,seq_reduce=0,read_reduce=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extra test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 1298 samples:\n",
      "AUC:0.8168   accuracy:74.7304%\n",
      "Precision when positive threshold at 0.5 is :74.9672% (total:763)\n",
      "Precision when positive threshold at 0.6 is :78.4226% (total:672)\n",
      "Precision when positive threshold at 0.8 is :86.0520% (total:423)\n",
      "Precision when positive threshold at 0.7 is :81.0435% (total:575)\n",
      "Precision when positive threshold at 0.9 is :91.8367% (total:245)\n",
      "Precision when positive threshold at 0.95 is :94.3548% (total:124)\n",
      "Precision when positive threshold at 0.98 is :100.0000% (total:46)\n",
      "Precision when positive threshold at 0.99 is :100.0000% (total:29)\n",
      "Precision when positive threshold at 0.995 is :100.0000% (total:18)\n",
      "Precision when positive threshold at 0.999 is :100.0000% (total:4)\n",
      "Precision when positive threshold at 0.9995 is :100.0000% (total:3)\n",
      "Precision when positive threshold at 0.9999 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.99995 is :100.0000% (total:1)\n"
     ]
    }
   ],
   "source": [
    "#trained on 20 reads, test on 20 reads\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_222000_60_20reads_9sites.pkl',weights_only=True))\n",
    "detailed_test(model,test_loader,device,seq_reduce=16,read_reduce=30,\\\n",
    "              curve_name='NSWord,20reads_9sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 1298 samples:\n",
      "AUC:0.8299   accuracy:76.1171%\n",
      "Precision when positive threshold at 0.5 is :74.7826% (total:805)\n",
      "Precision when positive threshold at 0.6 is :76.8056% (total:720)\n",
      "Precision when positive threshold at 0.8 is :85.8351% (total:473)\n",
      "Precision when positive threshold at 0.7 is :80.4487% (total:624)\n",
      "Precision when positive threshold at 0.9 is :91.0394% (total:279)\n",
      "Precision when positive threshold at 0.95 is :97.5000% (total:160)\n",
      "Precision when positive threshold at 0.98 is :100.0000% (total:62)\n",
      "Precision when positive threshold at 0.99 is :100.0000% (total:30)\n",
      "Precision when positive threshold at 0.995 is :100.0000% (total:16)\n",
      "Precision when positive threshold at 0.999 is :100.0000% (total:4)\n",
      "Precision when positive threshold at 0.9995 is :100.0000% (total:3)\n",
      "Precision when positive threshold at 0.9999 is :100.0000% (total:2)\n",
      "Precision when positive threshold at 0.99995 is :100.0000% (total:2)\n",
      "Precision when positive threshold at 0.99999 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.999995 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.999999 is :100.0000% (total:1)\n"
     ]
    }
   ],
   "source": [
    "#trained on 20 reads, test on 50 reads\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_222000_60_20reads_9sites.pkl',weights_only=True))\n",
    "detailed_test(model,test_loader,device,seq_reduce=16,read_reduce=0,\\\n",
    "              curve_name='NSWord,20reads_train_50reads_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 1298 samples:\n",
      "AUC:0.7793   accuracy:70.4160%\n",
      "Precision when positive threshold at 0.5 is :73.7921% (total:683)\n",
      "Precision when positive threshold at 0.6 is :75.8675% (total:634)\n",
      "Precision when positive threshold at 0.8 is :80.0830% (total:482)\n",
      "Precision when positive threshold at 0.7 is :77.5832% (total:571)\n",
      "Precision when positive threshold at 0.9 is :84.3243% (total:370)\n",
      "Precision when positive threshold at 0.95 is :86.0627% (total:287)\n",
      "Precision when positive threshold at 0.98 is :87.6404% (total:178)\n",
      "Precision when positive threshold at 0.99 is :90.3509% (total:114)\n",
      "Precision when positive threshold at 0.995 is :89.8734% (total:79)\n",
      "Precision when positive threshold at 0.999 is :88.8889% (total:36)\n",
      "Precision when positive threshold at 0.9995 is :81.8182% (total:22)\n",
      "Precision when positive threshold at 0.9999 is :77.7778% (total:9)\n",
      "Precision when positive threshold at 0.99995 is :85.7143% (total:7)\n",
      "Precision when positive threshold at 0.99999 is :100.0000% (total:4)\n",
      "Precision when positive threshold at 0.999995 is :100.0000% (total:3)\n",
      "Precision when positive threshold at 0.999999 is :100.0000% (total:2)\n"
     ]
    }
   ],
   "source": [
    "#use all 25 sites\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_222000_70_50reads_25sites.pkl',weights_only=True))\n",
    "detailed_test(model,test_loader,device,seq_reduce=0,read_reduce=0,\\\n",
    "              curve_name='NSWord,50reads_25sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 1298 samples:\n",
      "AUC:0.8416   accuracy:76.6564%\n",
      "Precision when positive threshold at 0.5 is :84.4068% (total:590)\n",
      "Precision when positive threshold at 0.6 is :85.5787% (total:527)\n",
      "Precision when positive threshold at 0.8 is :89.6254% (total:347)\n",
      "Precision when positive threshold at 0.7 is :87.6623% (total:462)\n",
      "Precision when positive threshold at 0.9 is :95.0276% (total:181)\n",
      "Precision when positive threshold at 0.95 is :96.2500% (total:80)\n",
      "Precision when positive threshold at 0.98 is :96.8750% (total:32)\n",
      "Precision when positive threshold at 0.99 is :100.0000% (total:19)\n",
      "Precision when positive threshold at 0.995 is :100.0000% (total:8)\n",
      "Precision when positive threshold at 0.999 is :100.0000% (total:2)\n",
      "Precision when positive threshold at 0.9995 is :100.0000% (total:2)\n"
     ]
    }
   ],
   "source": [
    "#just for renaming\n",
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_222000_50_50reads_9sites.pkl',weights_only=True))\n",
    "detailed_test(model,test_loader,device,seq_reduce=16,read_reduce=0,\\\n",
    "              curve_name='NSWord,50reads_9sites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Across cell line test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(HepG2_dataset) 230\n"
     ]
    }
   ],
   "source": [
    "RELOAD=0\n",
    "if RELOAD==1:\n",
    "    categories=['A','T','C','G']\n",
    "    unseen_test_seq_set=set()\n",
    "    for each in flattened_test_set:\n",
    "        indices=np.argmax(each['seq_feature'].cpu(),axis=1)\n",
    "        seq_lis=[categories[idx] for idx in indices]\n",
    "        seq=''.join(seq_lis)\n",
    "        unseen_test_seq_set.add(seq)\n",
    "    \n",
    "    HepG2_dataset=NanoDataset('./edata/DataSet/m6A','use_files_HepG2')\n",
    "    HepG2_dataset=FlattenedDataset(HepG2_dataset)\n",
    "    temp_pos_dataset=[]\n",
    "    temp_neg_dataset=[]\n",
    "    for each in HepG2_dataset:\n",
    "        if each['label']==1:\n",
    "            indices=np.argmax(each['seq_feature'].cpu(),axis=1)\n",
    "            seq_lis=[categories[idx] for idx in indices]\n",
    "            seq=''.join(seq_lis)\n",
    "            if seq in unseen_test_seq_set:\n",
    "                temp_pos_dataset.append(each)\n",
    "        else:\n",
    "            temp_neg_dataset.append(each)\n",
    "    temp_neg_dataset=random.sample(temp_neg_dataset,k=len(temp_pos_dataset))\n",
    "\n",
    "    HepG2_dataset=temp_pos_dataset+temp_neg_dataset\n",
    "    print('len(HepG2_dataset)',len(HepG2_dataset))\n",
    "    with open('./edata/Save_DataSet/m6A_NSWord_HepG2_set.pkl','wb') as f:\n",
    "        pickle.dump(HepG2_dataset,f)\n",
    "    HepG2_loader=DataLoader(HepG2_dataset,batch_size=5,shuffle=False)\n",
    "else:\n",
    "    with open('./edata/Save_DataSet/m6A_NSWord_HepG2_set.pkl','rb') as f:\n",
    "        HepG2_dataset=pickle.load(f)\n",
    "    print('len(HepG2_dataset)',len(HepG2_dataset))\n",
    "    HepG2_loader=DataLoader(HepG2_dataset,batch_size=5,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im total 230 samples:\n",
      "AUC:0.8221   accuracy:75.2174%\n",
      "Precision when positive threshold at 0.5 is :82.2222% (total:90)\n",
      "Precision when positive threshold at 0.6 is :83.7500% (total:80)\n",
      "Precision when positive threshold at 0.8 is :83.9286% (total:56)\n",
      "Precision when positive threshold at 0.7 is :85.5072% (total:69)\n",
      "Precision when positive threshold at 0.9 is :83.3333% (total:30)\n",
      "Precision when positive threshold at 0.95 is :85.7143% (total:14)\n",
      "Precision when positive threshold at 0.98 is :75.0000% (total:8)\n",
      "Precision when positive threshold at 0.99 is :100.0000% (total:5)\n",
      "Precision when positive threshold at 0.995 is :100.0000% (total:3)\n",
      "Precision when positive threshold at 0.999 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.9995 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.9999 is :100.0000% (total:1)\n",
      "Precision when positive threshold at 0.99995 is :100.0000% (total:1)\n"
     ]
    }
   ],
   "source": [
    "model=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model.load_state_dict(torch.load('./model/NSWord_222000_50_50reads_9sites.pkl',weights_only=True))\n",
    "detailed_test(model,HepG2_loader,device,seq_reduce=16,read_reduce=0,\\\n",
    "              curve_name='NSWord,HCT116_train_HepG2_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Shap explain 20reads (put on hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecode.explainer.NSWordExp_reads\n",
    "import ecode.explainer.NSWordExp_sites\n",
    "import importlib\n",
    "importlib.reload(ecode.explainer.NSWordExp_reads)\n",
    "importlib.reload(ecode.explainer.NSWordExp_sites)\n",
    "\n",
    "from ecode.explainer.NSWordExp_reads import NSWord_DeepEXP_reads\n",
    "from ecode.explainer.NSWordExp_sites import NSWord_DeepEXP_sites\n",
    "\n",
    "np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799 1298\n"
     ]
    }
   ],
   "source": [
    "print(len(flattened_train_set),len(flattened_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(background_set_20reads), 500\n",
      "len(sample_set_20reads), 100\n"
     ]
    }
   ],
   "source": [
    "read_reduce=30\n",
    "seq_reduce=16\n",
    "\n",
    "background_set_20reads=[]\n",
    "sample_set_20reads=[]\n",
    "\n",
    "background_set_size=500\n",
    "sample_set_size=100\n",
    "\n",
    "shuffled_flattened_train_set=flattened_train_set[random.sample(range(len(flattened_train_set)),background_set_size)]\n",
    "shuffled_flattened_test_set=flattened_test_set[random.sample(range(len(flattened_test_set)),sample_set_size)]\n",
    "\n",
    "for i in range(background_set_size):\n",
    "    l_dic=shuffled_flattened_train_set[i]\n",
    "    ap_dic={}\n",
    "    if seq_reduce==0:\n",
    "        ap_dic['seq_feature']=l_dic['seq_feature'].to(device)\n",
    "        ap_dic['seq_mask']=l_dic['seq_mask'].to(device)\n",
    "        ap_dic['nano_feature']=l_dic['nano_feature'][read_reduce:].to(device)\n",
    "        ap_dic['nano_mask']=l_dic['nano_mask'][read_reduce:].to(device)\n",
    "    else:\n",
    "        side_reduce=int(seq_reduce/2)\n",
    "        ap_dic['seq_feature']=l_dic['seq_feature'][side_reduce:-side_reduce].to(device)\n",
    "        ap_dic['seq_mask']=l_dic['seq_mask'][side_reduce:-side_reduce].to(device)\n",
    "        ap_dic['nano_feature']=l_dic['nano_feature'][read_reduce:,side_reduce:-side_reduce].to(device)\n",
    "        ap_dic['nano_mask']=l_dic['nano_mask'][read_reduce:,side_reduce:-side_reduce].to(device)\n",
    "    background_set_20reads.append(ap_dic)\n",
    "print(f'len(background_set_20reads), {len(background_set_20reads)}')\n",
    "\n",
    "for i in range(sample_set_size):\n",
    "    l_dic=shuffled_flattened_test_set[i]\n",
    "    ap_dic={}\n",
    "    ap_dic['label']=l_dic['label']\n",
    "    if seq_reduce==0:\n",
    "        ap_dic['seq_feature']=l_dic['seq_feature'].to(device)\n",
    "        ap_dic['seq_mask']=l_dic['seq_mask'].to(device)\n",
    "        ap_dic['nano_feature']=l_dic['nano_feature'][read_reduce:].to(device)\n",
    "        ap_dic['nano_mask']=l_dic['nano_mask'][read_reduce:].to(device)\n",
    "    else:\n",
    "        side_reduce=int(seq_reduce/2)\n",
    "        ap_dic['seq_feature']=l_dic['seq_feature'][side_reduce:-side_reduce].to(device)\n",
    "        ap_dic['seq_mask']=l_dic['seq_mask'][side_reduce:-side_reduce].to(device)\n",
    "        ap_dic['nano_feature']=l_dic['nano_feature'][read_reduce:,side_reduce:-side_reduce].to(device)\n",
    "        ap_dic['nano_mask']=l_dic['nano_mask'][read_reduce:,side_reduce:-side_reduce].to(device)\n",
    "    sample_set_20reads.append(ap_dic)\n",
    "print(f'len(sample_set_20reads), {len(sample_set_20reads)}')\n",
    "\n",
    "background_set_20reads=np.array(background_set_20reads)\n",
    "sample_set_20reads=np.array(sample_set_20reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20reads=Nano(c_s=4,c_x=3,c_emb=16,c_hidden_att=16,c_o=1,no_heads=8,blocks_lis=[2,2,2,0,0,0],\n",
    "            dropout=0.2,transition_n=2,inf=1e9,eps=1e-8,\n",
    "            clear_cache_between_blocks=False).to(device)\n",
    "model_20reads.load_state_dict(torch.load('./model/NSWord_222000_60_20reads_9sites.pkl',weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_20reads=NSWord_DeepEXP_reads(model_20reads,background_set_20reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values_20reads.shape (100, 20)\n"
     ]
    }
   ],
   "source": [
    "shap_values_20reads=explainer_20reads.shap_values(sample_set_20reads)\n",
    "shap_values_20reads=np.array(shap_values_20reads[0])\n",
    "print('shap_values_20reads.shape',shap_values_20reads.shape)\n",
    "with open('./edata/Save_for_drawing/NSWord_20reads_shap.pkl','wb') as f:\n",
    "    pickle.dump(shap_values_20reads,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_interaction_values.shape (50, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "#gradient_interaction_values_20reads=explainer_20reads.gradient_interaction_values(sample_set_20reads)\n",
    "#gradient_interaction_values_20reads=np.array(gradient_interaction_values_20reads[0])\n",
    "#print('gradient_interaction_values.shape',gradient_interaction_values_20reads.shape)\n",
    "#with open('./edata/Save_for_drawing/NSWord_20reads_interactions.pkl','wb') as f:\n",
    "#    pickle.dump(gradient_interaction_values_20reads,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
